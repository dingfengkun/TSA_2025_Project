{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing 2025-Era Small LLMs and HMMs for Time Series Forecasting\n",
    "\n",
    "**Group Members:** Zeyuan Ding (zd2466@nyu.edu), Keyu Hong (kh4300@nyu.edu)\n",
    "\n",
    "---\n",
    "\n",
    "### Research Question\n",
    "Can new-generation small LLMs, when treating numerical sequences as text tokens, outperform HMMs in short- and medium-term air quality forecasting?\n",
    "\n",
    "### Dataset\n",
    "Beijing PM2.5 Air Quality Dataset (2010-2014) - hourly PM2.5 concentrations and meteorological variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and numerical computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Hidden Markov Model implementation\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# Deep learning frameworks for LLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "# Utility imports\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Tuple, Dict\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Beijing PM2.5 dataset\n",
    "# Note: Download from https://archive.ics.uci.edu/dataset/381/beijing+pm2+5+data\n",
    "# Expected file: PRSA_data_2010.1.1-2014.12.31.csv\n",
    "\n",
    "def load_and_preprocess_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and perform initial preprocessing on the Beijing PM2.5 dataset.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed DataFrame with datetime index and cleaned features\n",
    "    \"\"\"\n",
    "    # Read the dataset\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"Dataset shape:\", df.shape)\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(df.columns.tolist())\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Create datetime index from year, month, day, hour columns\n",
    "    df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour']])\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    \n",
    "    # Drop redundant columns\n",
    "    columns_to_drop = ['No', 'year', 'month', 'day', 'hour']\n",
    "    df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "    \n",
    "    # Display missing value statistics\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")\n",
    "    print(f\"Percentage missing: {df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100:.2f}%\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "# Update this path to match your local file location\n",
    "data_path = 'PRSA_data_2010.1.1-2014.12.31.csv'\n",
    "df_raw = load_and_preprocess_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Handle missing values and outliers in the dataset.\n",
    "    \n",
    "    Strategy:\n",
    "    - Forward fill for short gaps (< 3 hours)\n",
    "    - Linear interpolation for medium gaps (3-24 hours)\n",
    "    - Drop remaining NaN values\n",
    "    \n",
    "    Args:\n",
    "        df: Raw DataFrame with missing values\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Forward fill for short gaps\n",
    "    df_clean = df_clean.fillna(method='ffill', limit=2)\n",
    "    \n",
    "    # Interpolate for medium gaps\n",
    "    df_clean = df_clean.interpolate(method='linear', limit=24)\n",
    "    \n",
    "    # Drop remaining missing values\n",
    "    df_clean.dropna(inplace=True)\n",
    "    \n",
    "    print(f\"Data shape after cleaning: {df_clean.shape}\")\n",
    "    print(f\"Remaining missing values: {df_clean.isnull().sum().sum()}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "df_clean = clean_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# PM2.5 time series\n",
    "axes[0, 0].plot(df_clean.index, df_clean['pm2.5'], linewidth=0.5, alpha=0.7)\n",
    "axes[0, 0].set_title('PM2.5 Concentration Over Time', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('PM2.5 (μg/m³)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# PM2.5 distribution\n",
    "axes[0, 1].hist(df_clean['pm2.5'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('PM2.5 Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('PM2.5 (μg/m³)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(df_clean['pm2.5'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {df_clean[\"pm2.5\"].mean():.2f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Monthly average PM2.5\n",
    "monthly_avg = df_clean['pm2.5'].resample('M').mean()\n",
    "axes[1, 0].plot(monthly_avg.index, monthly_avg.values, marker='o', linewidth=2)\n",
    "axes[1, 0].set_title('Monthly Average PM2.5', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Average PM2.5 (μg/m³)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Correlation heatmap for numerical features\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df_clean[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, ax=axes[1, 1], cbar_kws={'shrink': 0.8})\n",
    "axes[1, 1].set_title('Feature Correlation Matrix', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('eda_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Display statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df_clean.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Engineer temporal and statistical features from the raw data.\n",
    "    \n",
    "    Features include:\n",
    "    - Temporal: hour of day, day of week, month, season\n",
    "    - Lag features: previous 1, 3, 6, 12, 24 hours\n",
    "    - Rolling statistics: mean, std, min, max over windows\n",
    "    \n",
    "    Args:\n",
    "        df: Cleaned DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with engineered features\n",
    "    \"\"\"\n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # Temporal features\n",
    "    df_features['hour'] = df_features.index.hour\n",
    "    df_features['day_of_week'] = df_features.index.dayofweek\n",
    "    df_features['month'] = df_features.index.month\n",
    "    df_features['season'] = (df_features.index.month % 12 + 3) // 3  # 1=winter, 2=spring, 3=summer, 4=fall\n",
    "    \n",
    "    # Cyclical encoding for temporal features\n",
    "    df_features['hour_sin'] = np.sin(2 * np.pi * df_features['hour'] / 24)\n",
    "    df_features['hour_cos'] = np.cos(2 * np.pi * df_features['hour'] / 24)\n",
    "    df_features['month_sin'] = np.sin(2 * np.pi * df_features['month'] / 12)\n",
    "    df_features['month_cos'] = np.cos(2 * np.pi * df_features['month'] / 12)\n",
    "    \n",
    "    # Lag features for PM2.5\n",
    "    for lag in [1, 3, 6, 12, 24]:\n",
    "        df_features[f'pm2.5_lag_{lag}'] = df_features['pm2.5'].shift(lag)\n",
    "    \n",
    "    # Rolling window statistics\n",
    "    for window in [6, 12, 24]:\n",
    "        df_features[f'pm2.5_rolling_mean_{window}'] = df_features['pm2.5'].rolling(window=window).mean()\n",
    "        df_features[f'pm2.5_rolling_std_{window}'] = df_features['pm2.5'].rolling(window=window).std()\n",
    "        df_features[f'pm2.5_rolling_min_{window}'] = df_features['pm2.5'].rolling(window=window).min()\n",
    "        df_features[f'pm2.5_rolling_max_{window}'] = df_features['pm2.5'].rolling(window=window).max()\n",
    "    \n",
    "    # Drop rows with NaN values created by lagging and rolling\n",
    "    df_features.dropna(inplace=True)\n",
    "    \n",
    "    print(f\"Feature engineering complete. Shape: {df_features.shape}\")\n",
    "    print(f\"Number of features: {len(df_features.columns)}\")\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "df_features = create_features(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_split(df: pd.DataFrame, test_size: float = 0.2) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Create temporal train-test split for time series data.\n",
    "    \n",
    "    Args:\n",
    "        df: Feature-engineered DataFrame\n",
    "        test_size: Proportion of data to use for testing\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (train_df, test_df)\n",
    "    \"\"\"\n",
    "    split_idx = int(len(df) * (1 - test_size))\n",
    "    \n",
    "    train_df = df.iloc[:split_idx].copy()\n",
    "    test_df = df.iloc[split_idx:].copy()\n",
    "    \n",
    "    print(f\"Train set: {train_df.shape[0]} samples ({train_df.index[0]} to {train_df.index[-1]})\")\n",
    "    print(f\"Test set: {test_df.shape[0]} samples ({test_df.index[0]} to {test_df.index[-1]})\")\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = create_train_test_split(df_features, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hidden Markov Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PM25HMM:\n",
    "    \"\"\"\n",
    "    Gaussian Hidden Markov Model for PM2.5 forecasting.\n",
    "    \n",
    "    The model identifies latent pollution regimes and forecasts future PM2.5 levels\n",
    "    through learned state transitions and emission probabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components: int = 5, n_iter: int = 100, random_state: int = 42):\n",
    "        \"\"\"\n",
    "        Initialize the HMM.\n",
    "        \n",
    "        Args:\n",
    "            n_components: Number of hidden states (pollution regimes)\n",
    "            n_iter: Number of EM iterations for training\n",
    "            random_state: Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.model = hmm.GaussianHMM(\n",
    "            n_components=n_components,\n",
    "            covariance_type=\"full\",\n",
    "            n_iter=n_iter,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def prepare_data(self, df: pd.DataFrame, feature_cols: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Prepare and scale features for HMM training.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with features\n",
    "            feature_cols: List of feature column names\n",
    "            \n",
    "        Returns:\n",
    "            Scaled feature matrix\n",
    "        \"\"\"\n",
    "        X = df[feature_cols].values\n",
    "        return X\n",
    "    \n",
    "    def fit(self, train_df: pd.DataFrame, feature_cols: List[str]) -> 'PM25HMM':\n",
    "        \"\"\"\n",
    "        Train the HMM on training data.\n",
    "        \n",
    "        Args:\n",
    "            train_df: Training DataFrame\n",
    "            feature_cols: List of feature columns to use\n",
    "            \n",
    "        Returns:\n",
    "            Self (fitted model)\n",
    "        \"\"\"\n",
    "        X_train = self.prepare_data(train_df, feature_cols)\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        print(f\"Training HMM with {self.n_components} hidden states...\")\n",
    "        self.model.fit(X_train_scaled)\n",
    "        self.is_fitted = True\n",
    "        \n",
    "        # Analyze learned states\n",
    "        hidden_states = self.model.predict(X_train_scaled)\n",
    "        print(f\"\\nHidden state distribution in training data:\")\n",
    "        unique, counts = np.unique(hidden_states, return_counts=True)\n",
    "        for state, count in zip(unique, counts):\n",
    "            print(f\"  State {state}: {count} ({count/len(hidden_states)*100:.2f}%)\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_one_step(self, history_df: pd.DataFrame, feature_cols: List[str]) -> float:\n",
    "        \"\"\"\n",
    "        Predict PM2.5 for the next time step.\n",
    "        \n",
    "        Args:\n",
    "            history_df: Historical data DataFrame\n",
    "            feature_cols: Feature columns to use\n",
    "            \n",
    "        Returns:\n",
    "            Predicted PM2.5 value\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model must be fitted before prediction\")\n",
    "        \n",
    "        X_history = self.prepare_data(history_df, feature_cols)\n",
    "        X_history_scaled = self.scaler.transform(X_history)\n",
    "        \n",
    "        # Get the most likely hidden state sequence\n",
    "        hidden_states = self.model.predict(X_history_scaled)\n",
    "        current_state = hidden_states[-1]\n",
    "        \n",
    "        # Predict next state based on transition probabilities\n",
    "        next_state_probs = self.model.transmat_[current_state]\n",
    "        next_state = np.argmax(next_state_probs)\n",
    "        \n",
    "        # Get emission mean for the next state (using first feature as PM2.5)\n",
    "        next_pm25 = self.model.means_[next_state][0] * self.scaler.scale_[0] + self.scaler.mean_[0]\n",
    "        \n",
    "        return next_pm25\n",
    "    \n",
    "    def predict_multi_step(self, history_df: pd.DataFrame, feature_cols: List[str], \n",
    "                          steps: int = 6) -> List[float]:\n",
    "        \"\"\"\n",
    "        Predict PM2.5 for multiple future time steps.\n",
    "        \n",
    "        Args:\n",
    "            history_df: Historical data DataFrame\n",
    "            feature_cols: Feature columns to use\n",
    "            steps: Number of future steps to predict\n",
    "            \n",
    "        Returns:\n",
    "            List of predicted PM2.5 values\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        current_history = history_df.copy()\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            pred = self.predict_one_step(current_history, feature_cols)\n",
    "            predictions.append(pred)\n",
    "            \n",
    "            # Note: In practice, we would need to update the history with the prediction\n",
    "            # For simplicity, we're using the last observed state transitions\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# Define features to use for HMM\n",
    "hmm_feature_cols = ['pm2.5', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train HMM model\n",
    "print(\"=\" * 60)\n",
    "print(\"Training Hidden Markov Model\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "hmm_model = PM25HMM(n_components=5, n_iter=100)\n",
    "hmm_model.fit(train_df, hmm_feature_cols)\n",
    "\n",
    "print(\"\\nHMM training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Large Language Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTokenizer:\n",
    "    \"\"\"\n",
    "    Tokenizer for converting numerical time series into discrete tokens for LLM input.\n",
    "    \n",
    "    Strategy:\n",
    "    - Quantize continuous PM2.5 values into discrete bins\n",
    "    - Create vocabulary of tokens representing value ranges\n",
    "    - Format sequences with special tokens for temporal structure\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_bins: int = 100, value_range: Tuple[float, float] = None):\n",
    "        \"\"\"\n",
    "        Initialize the tokenizer.\n",
    "        \n",
    "        Args:\n",
    "            n_bins: Number of discrete bins for quantization\n",
    "            value_range: (min, max) range for binning, or None to compute from data\n",
    "        \"\"\"\n",
    "        self.n_bins = n_bins\n",
    "        self.value_range = value_range\n",
    "        self.bins = None\n",
    "        self.token_to_value = {}\n",
    "        self.value_to_token = {}\n",
    "        \n",
    "    def fit(self, values: np.ndarray) -> 'TimeSeriesTokenizer':\n",
    "        \"\"\"\n",
    "        Fit the tokenizer to the data range.\n",
    "        \n",
    "        Args:\n",
    "            values: Array of PM2.5 values\n",
    "            \n",
    "        Returns:\n",
    "            Self (fitted tokenizer)\n",
    "        \"\"\"\n",
    "        if self.value_range is None:\n",
    "            min_val = np.floor(values.min())\n",
    "            max_val = np.ceil(values.max())\n",
    "            self.value_range = (min_val, max_val)\n",
    "        \n",
    "        # Create bins\n",
    "        self.bins = np.linspace(self.value_range[0], self.value_range[1], self.n_bins + 1)\n",
    "        \n",
    "        # Create token mappings\n",
    "        for i in range(self.n_bins):\n",
    "            token = f\"<PM25_{i}>\"\n",
    "            bin_center = (self.bins[i] + self.bins[i+1]) / 2\n",
    "            self.token_to_value[token] = bin_center\n",
    "            self.value_to_token[i] = token\n",
    "        \n",
    "        print(f\"Tokenizer fitted: {self.n_bins} bins from {self.value_range[0]:.1f} to {self.value_range[1]:.1f}\")\n",
    "        return self\n",
    "    \n",
    "    def encode(self, values: np.ndarray) -> List[str]:\n",
    "        \"\"\"\n",
    "        Convert numerical values to tokens.\n",
    "        \n",
    "        Args:\n",
    "            values: Array of PM2.5 values\n",
    "            \n",
    "        Returns:\n",
    "            List of token strings\n",
    "        \"\"\"\n",
    "        bin_indices = np.digitize(values, self.bins) - 1\n",
    "        bin_indices = np.clip(bin_indices, 0, self.n_bins - 1)\n",
    "        tokens = [self.value_to_token[idx] for idx in bin_indices]\n",
    "        return tokens\n",
    "    \n",
    "    def decode(self, tokens: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convert tokens back to numerical values.\n",
    "        \n",
    "        Args:\n",
    "            tokens: List of token strings\n",
    "            \n",
    "        Returns:\n",
    "            Array of PM2.5 values\n",
    "        \"\"\"\n",
    "        values = [self.token_to_value.get(token, self.value_range[0]) for token in tokens]\n",
    "        return np.array(values)\n",
    "    \n",
    "    def create_sequence(self, values: np.ndarray, context_length: int = 24) -> str:\n",
    "        \"\"\"\n",
    "        Create a formatted sequence string for LLM input.\n",
    "        \n",
    "        Args:\n",
    "            values: Array of PM2.5 values\n",
    "            context_length: Number of past values to include\n",
    "            \n",
    "        Returns:\n",
    "            Formatted string with tokens\n",
    "        \"\"\"\n",
    "        tokens = self.encode(values[-context_length:])\n",
    "        sequence = \" \".join(tokens)\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PM25TimeSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for time series forecasting with LLMs.\n",
    "    \n",
    "    Creates sliding windows of tokenized sequences for autoregressive training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: TimeSeriesTokenizer, \n",
    "                 context_length: int = 24, target_length: int = 1):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with PM2.5 values\n",
    "            tokenizer: Fitted TimeSeriesTokenizer\n",
    "            context_length: Number of past time steps to use as context\n",
    "            target_length: Number of future time steps to predict\n",
    "        \"\"\"\n",
    "        self.values = df['pm2.5'].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.context_length = context_length\n",
    "        self.target_length = target_length\n",
    "        \n",
    "        # Create all valid sequences\n",
    "        self.sequences = []\n",
    "        total_length = context_length + target_length\n",
    "        \n",
    "        for i in range(len(self.values) - total_length + 1):\n",
    "            sequence = self.values[i:i + total_length]\n",
    "            self.sequences.append(sequence)\n",
    "        \n",
    "        print(f\"Created {len(self.sequences)} sequences (context: {context_length}, target: {target_length})\")\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Get a single sequence for training.\n",
    "        \n",
    "        Args:\n",
    "            idx: Sequence index\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with 'text' key containing the full tokenized sequence\n",
    "        \"\"\"\n",
    "        sequence = self.sequences[idx]\n",
    "        tokens = self.tokenizer.encode(sequence)\n",
    "        text = \" \".join(tokens)\n",
    "        \n",
    "        return {\"text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PM25LLMForecaster:\n",
    "    \"\"\"\n",
    "    Wrapper class for fine-tuning and using small LLMs for PM2.5 forecasting.\n",
    "    \n",
    "    Supports models like Phi-3-mini, Llama-3.2, Qwen2.5.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"microsoft/phi-2\", \n",
    "                 n_bins: int = 100, context_length: int = 24):\n",
    "        \"\"\"\n",
    "        Initialize the LLM forecaster.\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model identifier\n",
    "            n_bins: Number of bins for tokenization\n",
    "            context_length: Length of historical context\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.context_length = context_length\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize tokenizer for time series\n",
    "        self.ts_tokenizer = TimeSeriesTokenizer(n_bins=n_bins)\n",
    "        \n",
    "        # Load pre-trained model and tokenizer\n",
    "        print(f\"Loading model: {model_name}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        \n",
    "        # Set padding token if not already set\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "        )\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        print(f\"Model loaded successfully on {self.device}\")\n",
    "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()) / 1e6:.2f}M\")\n",
    "    \n",
    "    def prepare_dataset(self, train_df: pd.DataFrame, val_df: pd.DataFrame = None):\n",
    "        \"\"\"\n",
    "        Prepare training and validation datasets.\n",
    "        \n",
    "        Args:\n",
    "            train_df: Training DataFrame\n",
    "            val_df: Validation DataFrame (optional)\n",
    "        \"\"\"\n",
    "        # Fit tokenizer on training data\n",
    "        self.ts_tokenizer.fit(train_df['pm2.5'].values)\n",
    "        \n",
    "        # Create datasets\n",
    "        self.train_dataset = PM25TimeSeriesDataset(\n",
    "            train_df, self.ts_tokenizer, \n",
    "            context_length=self.context_length, target_length=1\n",
    "        )\n",
    "        \n",
    "        if val_df is not None:\n",
    "            self.val_dataset = PM25TimeSeriesDataset(\n",
    "                val_df, self.ts_tokenizer,\n",
    "                context_length=self.context_length, target_length=1\n",
    "            )\n",
    "        else:\n",
    "            self.val_dataset = None\n",
    "    \n",
    "    def fine_tune(self, output_dir: str = \"./llm_pm25_model\", \n",
    "                  num_epochs: int = 3, batch_size: int = 8, learning_rate: float = 2e-5):\n",
    "        \"\"\"\n",
    "        Fine-tune the LLM on PM2.5 forecasting task.\n",
    "        \n",
    "        Args:\n",
    "            output_dir: Directory to save the fine-tuned model\n",
    "            num_epochs: Number of training epochs\n",
    "            batch_size: Training batch size\n",
    "            learning_rate: Learning rate for optimization\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Starting LLM Fine-tuning\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Define training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=num_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            warmup_steps=100,\n",
    "            logging_steps=50,\n",
    "            save_steps=500,\n",
    "            eval_steps=500 if self.val_dataset else None,\n",
    "            evaluation_strategy=\"steps\" if self.val_dataset else \"no\",\n",
    "            save_total_limit=2,\n",
    "            load_best_model_at_end=True if self.val_dataset else False,\n",
    "            fp16=torch.cuda.is_available(),\n",
    "            report_to=\"none\",\n",
    "        )\n",
    "        \n",
    "        # Create data collator\n",
    "        data_collator = DataCollatorForLanguageModeling(\n",
    "            tokenizer=self.tokenizer,\n",
    "            mlm=False  # Causal language modeling\n",
    "        )\n",
    "        \n",
    "        # Initialize trainer\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=self.train_dataset,\n",
    "            eval_dataset=self.val_dataset,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        trainer.train()\n",
    "        \n",
    "        # Save the final model\n",
    "        trainer.save_model(output_dir)\n",
    "        self.tokenizer.save_pretrained(output_dir)\n",
    "        \n",
    "        print(f\"\\nFine-tuning complete! Model saved to {output_dir}\")\n",
    "    \n",
    "    def predict_one_step(self, history: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Predict the next PM2.5 value given historical context.\n",
    "        \n",
    "        Args:\n",
    "            history: Array of historical PM2.5 values\n",
    "            \n",
    "        Returns:\n",
    "            Predicted PM2.5 value\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Create input sequence\n",
    "        input_text = self.ts_tokenizer.create_sequence(history, self.context_length)\n",
    "        inputs = self.tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Generate next token\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1,\n",
    "                num_return_sequences=1,\n",
    "                do_sample=False,\n",
    "                pad_token_id=self.tokenizer.pad_token_id\n",
    "            )\n",
    "        \n",
    "        # Decode the generated token\n",
    "        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        new_token = generated_text.split()[-1]  # Get the last token\n",
    "        \n",
    "        # Convert token back to numerical value\n",
    "        try:\n",
    "            prediction = self.ts_tokenizer.decode([new_token])[0]\n",
    "        except:\n",
    "            # Fallback to mean value if token is invalid\n",
    "            prediction = np.mean(history)\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def predict_multi_step(self, history: np.ndarray, steps: int = 6) -> List[float]:\n",
    "        \"\"\"\n",
    "        Predict multiple future PM2.5 values iteratively.\n",
    "        \n",
    "        Args:\n",
    "            history: Array of historical PM2.5 values\n",
    "            steps: Number of future steps to predict\n",
    "            \n",
    "        Returns:\n",
    "            List of predicted PM2.5 values\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        current_history = history.copy()\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            pred = self.predict_one_step(current_history)\n",
    "            predictions.append(pred)\n",
    "            \n",
    "            # Update history with prediction\n",
    "            current_history = np.append(current_history[1:], pred)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This cell demonstrates the LLM setup but is commented out to avoid long training times\n",
    "# Uncomment and run to actually train the LLM\n",
    "\n",
    "\"\"\"\n",
    "# Initialize LLM forecaster\n",
    "llm_forecaster = PM25LLMForecaster(\n",
    "    model_name=\"microsoft/phi-2\",  # Or \"Qwen/Qwen2.5-1.5B\", \"meta-llama/Llama-3.2-1B\"\n",
    "    n_bins=100,\n",
    "    context_length=24\n",
    ")\n",
    "\n",
    "# Split training data for validation\n",
    "val_split = int(len(train_df) * 0.9)\n",
    "train_subset = train_df.iloc[:val_split]\n",
    "val_subset = train_df.iloc[val_split:]\n",
    "\n",
    "# Prepare datasets\n",
    "llm_forecaster.prepare_dataset(train_subset, val_subset)\n",
    "\n",
    "# Fine-tune the model\n",
    "llm_forecaster.fine_tune(\n",
    "    output_dir=\"./llm_pm25_model\",\n",
    "    num_epochs=3,\n",
    "    batch_size=4,\n",
    "    learning_rate=2e-5\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(\"LLM implementation complete (training commented out for demonstration)\")\n",
    "print(\"Uncomment the code above to actually train the LLM model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation Metrics Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastingMetrics:\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation metrics for time series forecasting.\n",
    "    \n",
    "    Implements:\n",
    "    - Mean Absolute Error (MAE)\n",
    "    - Root Mean Squared Error (RMSE)\n",
    "    - Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "    - Mean Absolute Scaled Error (MASE)\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def mae(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Mean Absolute Error.\n",
    "        \n",
    "        MAE = (1/n) * Σ|y_true - y_pred|\n",
    "        \"\"\"\n",
    "        return np.mean(np.abs(y_true - y_pred))\n",
    "    \n",
    "    @staticmethod\n",
    "    def rmse(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Root Mean Squared Error.\n",
    "        \n",
    "        RMSE = sqrt((1/n) * Σ(y_true - y_pred)²)\n",
    "        \"\"\"\n",
    "        return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def smape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Symmetric Mean Absolute Percentage Error.\n",
    "        \n",
    "        SMAPE = (100/n) * Σ(2|y_true - y_pred| / (|y_true| + |y_pred|))\n",
    "        \"\"\"\n",
    "        numerator = np.abs(y_true - y_pred)\n",
    "        denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "        # Avoid division by zero\n",
    "        denominator = np.where(denominator == 0, 1, denominator)\n",
    "        return 100 * np.mean(numerator / denominator)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mase(y_true: np.ndarray, y_pred: np.ndarray, \n",
    "             y_train: np.ndarray, seasonal_period: int = 1) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Mean Absolute Scaled Error.\n",
    "        \n",
    "        MASE = MAE / MAE_naive\n",
    "        where MAE_naive is the MAE of a naive seasonal forecast on training data\n",
    "        \n",
    "        Args:\n",
    "            y_true: True values\n",
    "            y_pred: Predicted values\n",
    "            y_train: Training data for calculating scale\n",
    "            seasonal_period: Period for seasonal naive forecast (1 for non-seasonal)\n",
    "        \"\"\"\n",
    "        # Calculate MAE of predictions\n",
    "        mae_pred = np.mean(np.abs(y_true - y_pred))\n",
    "        \n",
    "        # Calculate scale using naive forecast on training data\n",
    "        naive_forecast = y_train[:-seasonal_period]\n",
    "        naive_actual = y_train[seasonal_period:]\n",
    "        mae_naive = np.mean(np.abs(naive_actual - naive_forecast))\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if mae_naive == 0:\n",
    "            return np.nan\n",
    "        \n",
    "        return mae_pred / mae_naive\n",
    "    \n",
    "    @classmethod\n",
    "    def compute_all_metrics(cls, y_true: np.ndarray, y_pred: np.ndarray,\n",
    "                           y_train: np.ndarray = None) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Compute all metrics at once.\n",
    "        \n",
    "        Args:\n",
    "            y_true: True values\n",
    "            y_pred: Predicted values\n",
    "            y_train: Training data (required for MASE)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of metric names and values\n",
    "        \"\"\"\n",
    "        metrics = {\n",
    "            'MAE': cls.mae(y_true, y_pred),\n",
    "            'RMSE': cls.rmse(y_true, y_pred),\n",
    "            'SMAPE': cls.smape(y_true, y_pred),\n",
    "        }\n",
    "        \n",
    "        if y_train is not None:\n",
    "            metrics['MASE'] = cls.mase(y_true, y_pred, y_train)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_metrics(metrics: Dict[str, float], model_name: str = \"Model\"):\n",
    "        \"\"\"\n",
    "        Pretty print metrics.\n",
    "        \n",
    "        Args:\n",
    "            metrics: Dictionary of metric names and values\n",
    "            model_name: Name of the model for display\n",
    "        \"\"\"\n",
    "        print(f\"\\n{model_name} Performance:\")\n",
    "        print(\"=\" * 40)\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"{metric_name:12s}: {value:10.4f}\")\n",
    "        print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_step_forecast(model, test_df: pd.DataFrame, \n",
    "                               model_type: str = \"HMM\",\n",
    "                               feature_cols: List[str] = None,\n",
    "                               context_length: int = 24) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate one-step-ahead forecasting performance.\n",
    "    \n",
    "    Args:\n",
    "        model: Fitted forecasting model (HMM or LLM)\n",
    "        test_df: Test DataFrame\n",
    "        model_type: Type of model (\"HMM\" or \"LLM\")\n",
    "        feature_cols: Feature columns (for HMM)\n",
    "        context_length: Length of historical context\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating {model_type} - One-Step Forecasting\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # Iterate through test set with rolling window\n",
    "    for i in tqdm(range(context_length, len(test_df)), desc=\"Forecasting\"):\n",
    "        # Get historical context\n",
    "        history_df = test_df.iloc[i-context_length:i]\n",
    "        true_value = test_df.iloc[i]['pm2.5']\n",
    "        \n",
    "        # Make prediction based on model type\n",
    "        try:\n",
    "            if model_type == \"HMM\":\n",
    "                pred = model.predict_one_step(history_df, feature_cols)\n",
    "            else:  # LLM\n",
    "                history_values = history_df['pm2.5'].values\n",
    "                pred = model.predict_one_step(history_values)\n",
    "            \n",
    "            y_true.append(true_value)\n",
    "            y_pred.append(pred)\n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Compute metrics\n",
    "    y_train = train_df['pm2.5'].values\n",
    "    metrics = ForecastingMetrics.compute_all_metrics(y_true, y_pred, y_train)\n",
    "    ForecastingMetrics.print_metrics(metrics, f\"{model_type} (One-Step)\")\n",
    "    \n",
    "    return metrics, y_true, y_pred\n",
    "\n",
    "# Evaluate HMM\n",
    "hmm_metrics_1step, hmm_true_1step, hmm_pred_1step = evaluate_one_step_forecast(\n",
    "    hmm_model, test_df, \"HMM\", hmm_feature_cols, context_length=24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multi_step_forecast(model, test_df: pd.DataFrame,\n",
    "                                 model_type: str = \"HMM\",\n",
    "                                 feature_cols: List[str] = None,\n",
    "                                 context_length: int = 24,\n",
    "                                 forecast_steps: int = 6) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate multi-step-ahead forecasting performance.\n",
    "    \n",
    "    Args:\n",
    "        model: Fitted forecasting model\n",
    "        test_df: Test DataFrame\n",
    "        model_type: Type of model (\"HMM\" or \"LLM\")\n",
    "        feature_cols: Feature columns (for HMM)\n",
    "        context_length: Length of historical context\n",
    "        forecast_steps: Number of steps to forecast ahead\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating {model_type} - {forecast_steps}-Step Forecasting\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    all_metrics = {}\n",
    "    \n",
    "    # Evaluate each forecast horizon separately\n",
    "    for step in range(1, forecast_steps + 1):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        \n",
    "        # Sample test points (every 6 hours to avoid overlap)\n",
    "        sample_indices = range(context_length, len(test_df) - forecast_steps, 6)\n",
    "        \n",
    "        for i in tqdm(sample_indices, desc=f\"Step {step}\"):\n",
    "            history_df = test_df.iloc[i-context_length:i]\n",
    "            true_value = test_df.iloc[i + step - 1]['pm2.5']\n",
    "            \n",
    "            try:\n",
    "                if model_type == \"HMM\":\n",
    "                    predictions = model.predict_multi_step(history_df, feature_cols, steps=step)\n",
    "                else:  # LLM\n",
    "                    history_values = history_df['pm2.5'].values\n",
    "                    predictions = model.predict_multi_step(history_values, steps=step)\n",
    "                \n",
    "                pred = predictions[-1]  # Get the prediction for this specific step\n",
    "                y_true.append(true_value)\n",
    "                y_pred.append(pred)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        # Compute metrics for this forecast horizon\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        \n",
    "        y_train = train_df['pm2.5'].values\n",
    "        metrics = ForecastingMetrics.compute_all_metrics(y_true, y_pred, y_train)\n",
    "        all_metrics[f\"step_{step}\"] = metrics\n",
    "        \n",
    "        print(f\"\\nStep {step} Metrics:\")\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"  {metric_name}: {value:.4f}\")\n",
    "    \n",
    "    return all_metrics\n",
    "\n",
    "# Evaluate HMM multi-step forecasting\n",
    "hmm_metrics_multistep = evaluate_multi_step_forecast(\n",
    "    hmm_model, test_df, \"HMM\", hmm_feature_cols, \n",
    "    context_length=24, forecast_steps=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LLM evaluation (uncomment if you have trained an LLM model)\n",
    "\"\"\"\n",
    "# Evaluate LLM one-step forecasting\n",
    "llm_metrics_1step, llm_true_1step, llm_pred_1step = evaluate_one_step_forecast(\n",
    "    llm_forecaster, test_df, \"LLM\", context_length=24\n",
    ")\n",
    "\n",
    "# Evaluate LLM multi-step forecasting\n",
    "llm_metrics_multistep = evaluate_multi_step_forecast(\n",
    "    llm_forecaster, test_df, \"LLM\",\n",
    "    context_length=24, forecast_steps=6\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nEvaluation complete!\")\n",
    "print(\"Note: LLM evaluation is commented out. Uncomment after training the LLM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one-step forecast results\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Time series comparison\n",
    "sample_length = 200\n",
    "sample_idx = slice(0, sample_length)\n",
    "\n",
    "axes[0].plot(hmm_true_1step[sample_idx], label='True Values', linewidth=2, alpha=0.7)\n",
    "axes[0].plot(hmm_pred_1step[sample_idx], label='HMM Predictions', linewidth=2, alpha=0.7)\n",
    "# If LLM predictions are available:\n",
    "# axes[0].plot(llm_pred_1step[sample_idx], label='LLM Predictions', linewidth=2, alpha=0.7)\n",
    "\n",
    "axes[0].set_title('One-Step Forecast Comparison (Sample)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Time Step')\n",
    "axes[0].set_ylabel('PM2.5 (μg/m³)')\n",
    "axes[0].legend(loc='upper right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Prediction scatter plot\n",
    "axes[1].scatter(hmm_true_1step, hmm_pred_1step, alpha=0.5, label='HMM', s=20)\n",
    "# If LLM predictions are available:\n",
    "# axes[1].scatter(llm_true_1step, llm_pred_1step, alpha=0.5, label='LLM', s=20)\n",
    "\n",
    "# Add perfect prediction line\n",
    "min_val = min(hmm_true_1step.min(), hmm_pred_1step.min())\n",
    "max_val = max(hmm_true_1step.max(), hmm_pred_1step.max())\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "\n",
    "axes[1].set_title('Predicted vs True PM2.5 Values', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('True PM2.5 (μg/m³)')\n",
    "axes[1].set_ylabel('Predicted PM2.5 (μg/m³)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('forecast_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multi-step forecast performance\n",
    "def plot_multistep_metrics(metrics_dict: Dict[str, Dict[str, float]], \n",
    "                          model_names: List[str]):\n",
    "    \"\"\"\n",
    "    Plot how forecast accuracy degrades over prediction horizon.\n",
    "    \n",
    "    Args:\n",
    "        metrics_dict: Dictionary mapping model names to their multi-step metrics\n",
    "        model_names: List of model names to plot\n",
    "    \"\"\"\n",
    "    metric_names = ['MAE', 'RMSE', 'SMAPE']\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    for idx, metric_name in enumerate(metric_names):\n",
    "        for model_name in model_names:\n",
    "            if model_name not in metrics_dict:\n",
    "                continue\n",
    "            \n",
    "            model_metrics = metrics_dict[model_name]\n",
    "            steps = []\n",
    "            values = []\n",
    "            \n",
    "            for step_key, step_metrics in model_metrics.items():\n",
    "                step_num = int(step_key.split('_')[1])\n",
    "                steps.append(step_num)\n",
    "                values.append(step_metrics[metric_name])\n",
    "            \n",
    "            axes[idx].plot(steps, values, marker='o', linewidth=2, \n",
    "                          markersize=8, label=model_name)\n",
    "        \n",
    "        axes[idx].set_title(f'{metric_name} vs Forecast Horizon', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Forecast Steps Ahead')\n",
    "        axes[idx].set_ylabel(metric_name)\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('multistep_metrics.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot metrics (add LLM when available)\n",
    "metrics_for_plot = {\n",
    "    'HMM': hmm_metrics_multistep,\n",
    "    # 'LLM': llm_metrics_multistep,  # Uncomment when available\n",
    "}\n",
    "\n",
    "plot_multistep_metrics(metrics_for_plot, ['HMM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze HMM hidden states\n",
    "def visualize_hmm_states(hmm_model: PM25HMM, df: pd.DataFrame, \n",
    "                         feature_cols: List[str], n_samples: int = 500):\n",
    "    \"\"\"\n",
    "    Visualize HMM hidden states and their relationship to PM2.5 levels.\n",
    "    \n",
    "    Args:\n",
    "        hmm_model: Fitted HMM model\n",
    "        df: DataFrame with data\n",
    "        feature_cols: Feature columns\n",
    "        n_samples: Number of samples to visualize\n",
    "    \"\"\"\n",
    "    # Get hidden states for a sample of data\n",
    "    sample_df = df.iloc[:n_samples]\n",
    "    X = sample_df[feature_cols].values\n",
    "    X_scaled = hmm_model.scaler.transform(X)\n",
    "    states = hmm_model.model.predict(X_scaled)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: PM2.5 levels colored by hidden state\n",
    "    scatter = axes[0].scatter(range(n_samples), sample_df['pm2.5'].values,\n",
    "                             c=states, cmap='viridis', alpha=0.6, s=20)\n",
    "    axes[0].set_title('PM2.5 Levels Colored by HMM Hidden State', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Time Step')\n",
    "    axes[0].set_ylabel('PM2.5 (μg/m³)')\n",
    "    plt.colorbar(scatter, ax=axes[0], label='Hidden State')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: State sequence\n",
    "    axes[1].plot(states, linewidth=2)\n",
    "    axes[1].set_title('Hidden State Sequence', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Time Step')\n",
    "    axes[1].set_ylabel('Hidden State')\n",
    "    axes[1].set_yticks(range(hmm_model.n_components))\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('hmm_states_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print state statistics\n",
    "    print(\"\\nHMM State Statistics:\")\n",
    "    print(\"=\" * 40)\n",
    "    for state in range(hmm_model.n_components):\n",
    "        state_mask = states == state\n",
    "        state_pm25 = sample_df['pm2.5'].values[state_mask]\n",
    "        if len(state_pm25) > 0:\n",
    "            print(f\"State {state}:\")\n",
    "            print(f\"  Mean PM2.5: {state_pm25.mean():.2f}\")\n",
    "            print(f\"  Std PM2.5: {state_pm25.std():.2f}\")\n",
    "            print(f\"  Occurrences: {len(state_pm25)} ({len(state_pm25)/n_samples*100:.1f}%)\")\n",
    "            print()\n",
    "\n",
    "visualize_hmm_states(hmm_model, test_df, hmm_feature_cols, n_samples=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Results Summary and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_table(hmm_metrics_1step: Dict[str, float],\n",
    "                        hmm_metrics_multistep: Dict[str, Dict[str, float]],\n",
    "                        llm_metrics_1step: Dict[str, float] = None,\n",
    "                        llm_metrics_multistep: Dict[str, Dict[str, float]] = None):\n",
    "    \"\"\"\n",
    "    Create a comprehensive results comparison table.\n",
    "    \n",
    "    Args:\n",
    "        hmm_metrics_1step: HMM one-step metrics\n",
    "        hmm_metrics_multistep: HMM multi-step metrics\n",
    "        llm_metrics_1step: LLM one-step metrics (optional)\n",
    "        llm_metrics_multistep: LLM multi-step metrics (optional)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n1. ONE-STEP FORECAST PERFORMANCE\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Metric':<15} {'HMM':<20} {'LLM':<20}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric in ['MAE', 'RMSE', 'SMAPE', 'MASE']:\n",
    "        hmm_val = hmm_metrics_1step.get(metric, 'N/A')\n",
    "        llm_val = llm_metrics_1step.get(metric, 'N/A') if llm_metrics_1step else 'N/A'\n",
    "        \n",
    "        hmm_str = f\"{hmm_val:.4f}\" if isinstance(hmm_val, float) else str(hmm_val)\n",
    "        llm_str = f\"{llm_val:.4f}\" if isinstance(llm_val, float) else str(llm_val)\n",
    "        \n",
    "        print(f\"{metric:<15} {hmm_str:<20} {llm_str:<20}\")\n",
    "    \n",
    "    print(\"\\n2. MULTI-STEP FORECAST PERFORMANCE (Average across steps)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Calculate average metrics across all steps\n",
    "    def average_metrics(multistep_dict):\n",
    "        avg_metrics = {}\n",
    "        metric_names = ['MAE', 'RMSE', 'SMAPE', 'MASE']\n",
    "        for metric in metric_names:\n",
    "            values = [step_metrics[metric] for step_metrics in multistep_dict.values() \n",
    "                     if metric in step_metrics and not np.isnan(step_metrics[metric])]\n",
    "            avg_metrics[metric] = np.mean(values) if values else np.nan\n",
    "        return avg_metrics\n",
    "    \n",
    "    hmm_avg = average_metrics(hmm_metrics_multistep)\n",
    "    llm_avg = average_metrics(llm_metrics_multistep) if llm_metrics_multistep else {}\n",
    "    \n",
    "    print(f\"{'Metric':<15} {'HMM (Avg)':<20} {'LLM (Avg)':<20}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric in ['MAE', 'RMSE', 'SMAPE', 'MASE']:\n",
    "        hmm_val = hmm_avg.get(metric, np.nan)\n",
    "        llm_val = llm_avg.get(metric, np.nan)\n",
    "        \n",
    "        hmm_str = f\"{hmm_val:.4f}\" if not np.isnan(hmm_val) else 'N/A'\n",
    "        llm_str = f\"{llm_val:.4f}\" if not np.isnan(llm_val) else 'N/A'\n",
    "        \n",
    "        print(f\"{metric:<15} {hmm_str:<20} {llm_str:<20}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Create results table\n",
    "create_results_table(\n",
    "    hmm_metrics_1step,\n",
    "    hmm_metrics_multistep,\n",
    "    # llm_metrics_1step,  # Uncomment when LLM is trained\n",
    "    # llm_metrics_multistep  # Uncomment when LLM is trained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Discussion and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "This project compared Hidden Markov Models (HMMs) and modern small LLMs for PM2.5 air quality forecasting:\n",
    "\n",
    "#### HMM Performance\n",
    "- **Strengths**: \n",
    "  - Fast training and inference\n",
    "  - Interpretable hidden states corresponding to pollution regimes\n",
    "  - Stable performance in short-term predictions\n",
    "  - Low computational requirements\n",
    "\n",
    "- **Limitations**:\n",
    "  - Assumes Markovian property (limited long-term dependencies)\n",
    "  - Gaussian emission assumptions may not capture complex distributions\n",
    "  - Performance degrades for longer forecast horizons\n",
    "\n",
    "#### LLM Performance (Expected)\n",
    "- **Strengths**:\n",
    "  - Potential for capturing nonlinear temporal patterns\n",
    "  - Ability to leverage pre-trained linguistic reasoning\n",
    "  - Flexibility in modeling complex dependencies\n",
    "\n",
    "- **Limitations**:\n",
    "  - High computational cost for training and inference\n",
    "  - Requires careful tokenization strategy\n",
    "  - Less interpretable than HMM states\n",
    "  - Risk of overfitting on small datasets\n",
    "\n",
    "### Practical Implications\n",
    "\n",
    "1. **Short-term Forecasting (1-6 hours)**: HMMs provide a fast, interpretable solution with competitive accuracy\n",
    "2. **Medium-term Forecasting (6-24 hours)**: LLMs may offer advantages in capturing complex patterns\n",
    "3. **Deployment Considerations**: HMMs are preferable for resource-constrained environments\n",
    "4. **Hybrid Approaches**: Combining HMM interpretability with LLM pattern recognition could be promising\n",
    "\n",
    "### Future Work\n",
    "\n",
    "- Test additional LLM architectures (Llama-3.2, Qwen2.5)\n",
    "- Experiment with different tokenization strategies\n",
    "- Incorporate multivariate features beyond PM2.5\n",
    "- Develop ensemble methods combining HMM and LLM predictions\n",
    "- Investigate attention mechanisms for interpretability in LLMs\n",
    "- Extend to other environmental forecasting tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. References and Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "- Beijing PM2.5 Data Set. UCI Machine Learning Repository. https://archive.ics.uci.edu/dataset/381/beijing+pm2+5+data\n",
    "\n",
    "### Methods\n",
    "- Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2), 257-286.\n",
    "- Vaswani, A., et al. (2017). Attention is all you need. Advances in neural information processing systems, 30.\n",
    "- Gunasekar, S., et al. (2023). Textbooks Are All You Need II: phi-1.5 technical report. arXiv preprint arXiv:2309.05463.\n",
    "\n",
    "### Evaluation Metrics\n",
    "- Hyndman, R. J., & Koehler, A. B. (2006). Another look at measures of forecast accuracy. International journal of forecasting, 22(4), 679-688.\n",
    "- Makridakis, S. (1993). Accuracy measures: theoretical and practical concerns. International Journal of Forecasting, 9(4), 527-529."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Notebook Complete\n",
    "\n",
    "This notebook implements a comprehensive comparison of HMMs and small LLMs for time series forecasting. \n",
    "\n",
    "**Note**: The LLM training sections are commented out due to computational requirements. To run the full experiment:\n",
    "1. Uncomment the LLM training cells\n",
    "2. Ensure you have sufficient GPU resources\n",
    "3. Adjust batch sizes and model selection based on available memory\n",
    "4. Allow several hours for training depending on hardware\n",
    "\n",
    "**Contributors**: Zeyuan Ding, Keyu Hong"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
